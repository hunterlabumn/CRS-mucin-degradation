---
title: "CRS MMM Enrichment Sequence Analysis - DADA2 and Phyloseq"
---

```{r}
.cran_packages <- c("tidyverse", "gridExtra", "ips")
.bioc_packages <- c("dada2", "phyloseq", "DECIPHER", "phangorn", "ShortRead")

.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
   BiocManager::install(.bioc_packages[!.inst], quietly = FALSE)
}
# Load packages into session, and print package version
sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)

# Setting seed for reproducibility
set.seed(022019)
```
# Trim and Filter
## Run BWTM2
```{r}
path_1 <- "../data/fastq/RUN_BWTM2/cutadapt/" #Place where gzipped raw fastq files are kept
```
```{r}
fastqFs_1 <- sort(list.files(path_1, pattern="_R1_001.fastq.gz", full.names = F))
fastqRs_1 <- sort(list.files(path_1, pattern="_R2_001.fastq.gz", full.names = F))
if(length(fastqFs_1) != length(fastqRs_1)) stop("Forward and reverse files do not match.")

filtpath_1 <- file.path(path_1, "filtered") # Filtered forward files go into the pathF/filtered/ subdirectory
# Filtering: THESE PARAMETERS ARE RUN SPECIFIC DATASETS
out_1 <- filterAndTrim(fwd=file.path(path_1, fastqFs_1), filt=file.path(filtpath_1, fastqFs_1),
              rev=file.path(path_1, fastqRs_1), filt.rev=file.path(filtpath_1, fastqRs_1),
              truncLen=c(220,180), 
              maxEE=5,
              rm.phix=TRUE,
              compress=TRUE, verbose=TRUE, multithread=TRUE)
head(out_1)
```
## Run CCVK7
```{r}
path_2 <- "../data/fastq/RUN_CCVK7/cutadapt/" #Place where gzipped raw fastq files are kept
```
```{r}
fastqFs_2 <- sort(list.files(path_2, pattern="_R1_001.fastq.gz", full.names = F))
fastqRs_2 <- sort(list.files(path_2, pattern="_R2_001.fastq.gz", full.names = F))
if(length(fastqFs_2) != length(fastqRs_2)) stop("Forward and reverse files do not match.")

filtpath_2 <- file.path(path_2, "filtered") # Filtered forward files go into the pathF/filtered/ subdirectory
# Filtering: THESE PARAMETERS ARE RUN SPECIFIC DATASETS
out_2 <- filterAndTrim(fwd=file.path(path_2, fastqFs_2), filt=file.path(filtpath_2, fastqFs_2),
              rev=file.path(path_2, fastqRs_2), filt.rev=file.path(filtpath_2, fastqRs_2),
              truncLen=c(220,180), 
              maxEE=5,
              rm.phix=TRUE,
              compress=TRUE, verbose=TRUE, multithread=TRUE)
head(out_2)
```

# Infer Sequence Variants
## Run 1
```{r}
# File parsing
filtFs_1 <- list.files(filtpath_1, pattern="_R1_001.fastq.gz", full.names = TRUE)
filtRs_1 <- list.files(filtpath_1, pattern="_R2_001.fastq.gz", full.names = TRUE)
sampleNames_1 <- sapply(strsplit(basename(filtFs_1), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
sampleNamesR_1 <- sapply(strsplit(basename(filtRs_1), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
if(!identical(sampleNames_1, sampleNamesR_1)) stop("Forward and reverse files do not match.")
names(filtFs_1) <- sampleNames_1
names(filtRs_1) <- sampleNames_1
set.seed(100)
# Learn forward error rates
errF_1 <- learnErrors(filtFs_1, nbases=1e8, multithread=TRUE)
# Learn reverse error rates
errR_1 <- learnErrors(filtRs_1, nbases=1e8, multithread=TRUE)
```
## Run 2
```{r}
# File parsing
filtFs_2 <- list.files(filtpath_2, pattern="_R1_001.fastq.gz", full.names = TRUE)
filtRs_2 <- list.files(filtpath_2, pattern="_R2_001.fastq.gz", full.names = TRUE)
sampleNames_2 <- sapply(strsplit(basename(filtFs_2), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
sampleNamesR_2 <- sapply(strsplit(basename(filtRs_2), "_"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz
if(!identical(sampleNames_2, sampleNamesR_2)) stop("Forward and reverse files do not match.")
names(filtFs_2) <- sampleNames_2
names(filtRs_2) <- sampleNames_2
set.seed(100)
# Learn forward error rates
errF_2 <- learnErrors(filtFs_2, nbases=1e8, multithread=TRUE)
# Learn reverse error rates
errR_2 <- learnErrors(filtRs_2, nbases=1e8, multithread=TRUE)
```
## Error Plots 
Let's look at the error profiles for each of the dada2 runs
```{r}
plotErrors(errF_1, nominalQ=TRUE)
plotErrors(errF_2, nominalQ=TRUE)
```
# Sample Inference
## Run 1
```{r}
dadaFs_1 <- dada(filtFs_1, err=errF_1, multithread=TRUE)
dadaRs_1 <- dada(filtRs_1, err=errR_1, multithread=TRUE)
```
## Run 2
```{r}
dadaFs_2 <- dada(filtFs_2, err=errF_2, multithread=TRUE)
dadaRs_2 <- dada(filtRs_2, err=errR_2, multithread=TRUE)
```
# Merge sequences and make tables
```{r}
# Filter out all sequences not within length 245-255 bp, Target is 252bp, with added 10bo of length on either side
MINLEN <- 250
MAXLEN <- 256
```
## Run 1
```{r}
mergers_1 <- mergePairs(dadaFs_1, filtFs_1, dadaRs_1, filtRs_1, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers_1[[1]])
seqtab_1 <- makeSequenceTable(mergers_1)
seqtab_size_filt_1 <- seqtab_1[ ,nchar(colnames(seqtab_1)) %in% seq (MINLEN,MAXLEN)]
# Chimera Removal
seqtab_size_filt_nochim_1 <- removeBimeraDenovo(seqtab_size_filt_1, method="consensus", multithread=TRUE)
# Look at fraction of chimeras. Here, chimeras made up about 13.8% of the sequences, but that was only about 2% of total sequence reads
dim(seqtab_size_filt_1)
dim(seqtab_size_filt_nochim_1)
sum(seqtab_size_filt_nochim_1)/sum(seqtab_size_filt_1)
```
## Run 2
```{r}
mergers_2 <- mergePairs(dadaFs_2, filtFs_2, dadaRs_2, filtRs_2, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers_2[[1]])
seqtab_2 <- makeSequenceTable(mergers_2)
seqtab_size_filt_2 <- seqtab_2[ ,nchar(colnames(seqtab_2)) %in% seq (MINLEN,MAXLEN)]
# Chimera Removal
seqtab_size_filt_nochim_2 <- removeBimeraDenovo(seqtab_size_filt_2, method="consensus", multithread=TRUE)
# Look at fraction of chimeras. Here, chimeras made up about 13.8% of the sequences, but that was only about 2% of total sequence reads
dim(seqtab_size_filt_2)
dim(seqtab_size_filt_nochim_2)
sum(seqtab_size_filt_nochim_2)/sum(seqtab_size_filt_2)
```

# Track Reads through pipeline
```{r}
getN <- function(x) sum(getUniques(x))
# Run1
track_1 <- cbind(out_1, sapply(dadaFs_1, getN), sapply(dadaRs_1, getN), sapply(mergers_1, getN), rowSums(seqtab_size_filt_nochim_1))
colnames(track_1) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")
rownames(track_1) <- sampleNames_1

# Run2
track_2 <- cbind(out_2, sapply(dadaFs_2, getN), sapply(dadaRs_2, getN), sapply(mergers_2, getN), rowSums(seqtab_size_filt_nochim_2))
colnames(track_2) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")
rownames(track_2) <- sampleNames_2

# Combine dataframes and calculate percent reads kept.
track_all <- rbind(track_1, track_2)
track_all <- as.data.frame(track_all)
track_all <- rownames_to_column(track_all, "sample")
colnames(track_all)
track_all <- track_all %>% mutate(perc_original_sequences = nochim/input*100)

```
```{r}
write_csv(track_all, "../data/DADA2/DADA2_Tracking_MAR2020.csv")
```
# Combine all sequence tables
```{r}
seqtab <- mergeSequenceTables(seqtab_size_filt_nochim_1,
                              seqtab_size_filt_nochim_2 
                             )
saveRDS(seqtab, "../data/DADA2/seqtab_MAR2020.rds")
```
# Assign Taxonomy 


```{r}
seqtab <- readRDS("../data/DADA2/seqtab_MAR2020.rds")
```


## SILVA train set
```{r}
# Assign taxonomy SILVA Train Set
tax_silva <- assignTaxonomy(seqtab, "~/Documents/MICaB/Hunter_Lab/taxonomyTrainingSets/silva_nr_v132_train_set.fa.gz", multithread=TRUE)
colnames(tax_silva) <- c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus")

## Add species assignment to taxonomy table: https://benjjneb.github.io/dada2/assign.html#species-assignment
tax_species_silva <- addSpecies(tax_silva, "~/Documents/MICaB/Hunter_Lab/taxonomyTrainingSets/silva_species_assignment_v132.fa.gz", verbose=TRUE, allowMultiple = FALSE)
colnames(tax_species_silva)  <- c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species")
unname(head(tax_species_silva))
# Write to disk
saveRDS(tax_species_silva, "../data/DADA2/tax_species_final_silva_MAR2020.rds")
```

## Assign Species with HOMD train set
```{r}
## Add species assignment to taxonomy table: https://benjjneb.github.io/dada2/assign.html#species-assignment
tax_species_silva_HOMD <- addSpecies(tax_silva, "~/Documents/MICaB/Hunter_Lab/taxonomyTrainingSets/HOMD_16S_rRNA_RefSeq_V15.1.p9_dada2_addspecies.fasta", verbose=TRUE, allowMultiple = FALSE)
colnames(tax_species_silva_HOMD) <- c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species_HOMD")
unname(head(tax_species_silva_HOMD))
```
I want to keep the SILVA assigned species, but then add the HOMD assigned species as well
```{r}
#make rownames for ASVs for each species level taxa table
tax_species_silva_df <- as.data.frame(tax_species_silva) %>%
  rownames_to_column('ASV')
dim(tax_species_silva_df)

tax_species_silva_HOMD_df <- as.data.frame(tax_species_silva_HOMD) %>%
  rownames_to_column('ASV')
dim(tax_species_silva_HOMD_df)

tax_species_silva_HOMD_df_join <- full_join(x = tax_species_silva_df, y = tax_species_silva_HOMD_df, 
                                            by = c("ASV","Kingdom", "Phylum", "Class", "Order", "Family", "Genus"))
tax_species_silva_HOMD_df_join[tax_species_silva_HOMD_df_join == "cf."] <- NA
tax_species_silva_HOMD_df_join[tax_species_silva_HOMD_df_join == "sp."] <- NA

dim(tax_species_silva_HOMD_df_join)
```

```{r}
tax_species_silva_HOMD_df_join <- tax_species_silva_HOMD_df_join %>%
  mutate(DB = ifelse(!is.na(Species) & !is.na(Species_HOMD), "Both",
                     ifelse(!is.na(Species), "SILVA",
                            ifelse(!is.na(Species_HOMD), "HOMD", NA))))
```

```{r}
# If there is no species assignment in the Species_SILVA column, check the Species_HOMD column. If the Species_HOMD column says NA or sp. assign NA.
tax_species_silva_HOMD_df_join_newspecies <- tax_species_silva_HOMD_df_join %>%
  mutate(SpeciesCombo = ifelse(!is.na(Species), as.character(Species), as.character(Species_HOMD))) %>%
  select(ASV, Kingdom, Phylum, Class, Order, Family, Genus, SpeciesCombo, DB) %>%
  dplyr::rename(Species = SpeciesCombo) %>%
  column_to_rownames('ASV') %>%
  as.matrix()

# Write to disk
saveRDS(tax_species_silva_HOMD_df_join_newspecies, "../data/DADA2/tax_species_final_silva_HOMD_MAR2020.rds")
```

# Evaluate Tax Addition using HOMD

Make a table where the SILVA species assignment was NA, but the HOMD assignment was not. Count how many rows (ASVs).
```{r}
speciesCompare <- tax_species_silva_HOMD_df_join %>%
  filter(is.na(Species) & !is.na(Species_HOMD))
dim(speciesCompare)
```

# Summary
* There were no disagreements between species assinments shared by both the SILVA and HOMD databases
* There were more species assignments made from the SILVA database, but 
* 127 ASVs were assigned species from the HOMD database that were not in the SILVA species assignments

How many rows were not NA in the Species column for the SILVA species dataframe?
```{r}
length(which(!is.na(tax_species_silva_df$Species)))
```
How many rows were not NA in the Species column for the HOMD species dataframe?
```{r}
length(which(!is.na(tax_species_silva_HOMD_df$Species_HOMD)))
```
Do these numbers remain consistent when the tables are joined together?
```{r}
length(which(!is.na(tax_species_silva_HOMD_df_join$Species)))
length(which(!is.na(tax_species_silva_HOMD_df_join$Species_HOMD)))
```
Yes, they do.

# Construct phylogenetic tree using the Phangorn R package (method suggested by Callahan/Holmes https://f1000research.com/articles/5-1492/v2)
```{r}
# seqtab is the sample:ASV table made in DADA2 - it should contain all samples and ASVs
seqs <- getSequences(seqtab)
names(seqs) <- seqs # This propogates the tip labels of the tree
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA)

phang.align <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phang.align)
treeNJ <- NJ(dm)
fit = pml(treeNJ, data=phang.align)
fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
                      rearrangement = "stochastic", control = pml.control(trace = 0))
detach("package:phangorn", unload=TRUE)
saveRDS(fitGTR, "../data/DADA2/fitGTR_MAR2020.rds")
```